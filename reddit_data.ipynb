{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3a1faff-8be8-4318-96e9-1d5d25e8174c",
   "metadata": {},
   "source": [
    "![reddit banner](https://cdn.dribbble.com/users/1761084/screenshots/3587716/reddit.gtif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8602a503-762b-4339-acd7-bf127bc4928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing important libraries\n",
    "import praw\n",
    "import pandas as pd\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af3b82a9-f3ec-4b06-a8a8-e284c894f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reading configuration files for Reddit Credentials\n",
    "config = configparser.ConfigParser()\n",
    "config.read('reddit_credentials.ini')\n",
    "\n",
    "# Storing credential info in local variables\n",
    "user_agent = config.get('credentials', 'user_agent')\n",
    "client_id = config.get('credentials', 'client_id')\n",
    "client_secret = config.get('credentials', 'client_secret')\n",
    "redirect_url = config.get('credentials', 'redirect_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07f12986-0fd2-4f5a-b193-8a220828ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating read-only Reddit instance\n",
    "reddit = praw.Reddit(user_agent = user_agent,\n",
    "                    client_id = client_id,\n",
    "                    client_secret = client_secret,\n",
    "                    redirect_url = redirect_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87bd0c9-46c4-49c2-9981-c114bd9331cd",
   "metadata": {},
   "source": [
    "## Extracting Comments\n",
    "For our project we are going to use top 3 most popular Reddit communities -\n",
    "* Machine Learning - [r/MachineLearning](https://www.reddit.com/r/MachineLearning/)\n",
    "* Artificial Intelligence - [r/artificial](https://www.reddit.com/r/Artificial/)\n",
    "* Data Science - [r/DataScience](https://www.reddit.com/r/DataScience/)\n",
    "\n",
    "We will extract top 1000 post of all time from each sub-reddit to create our dataset along with some other useful information like Post URL (& ID), User posted, Post title, number of comments, time created, upvote ratio and score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4eefec6b-326b-4e7a-8fb0-a97fcd76c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting top 1000 posts from each subreddit\n",
    "posts = reddit.subreddit('MachineLearning+artificial+datascience').top(time_filter = 'all', limit = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64308ea1-fd7c-4c15-a847-89aca16d1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creting DataFrame of the top posts along with other attributes for analysis\n",
    "\n",
    "posts_list = []\n",
    "\n",
    "for post in posts:\n",
    "    posts_list.append({\n",
    "        'post_id' : post.id,\n",
    "        'post_title' : post.title,\n",
    "        'subreddit' : post.subreddit,\n",
    "        'time_created' : post.created_utc,\n",
    "        'post_url' : post.url,\n",
    "        'flair_text' : post.link_flair_text,\n",
    "        'score' : post.score,\n",
    "        'comments' : post.num_comments,\n",
    "        'upvote_ratio' : post.upvote_ratio\n",
    "    })\n",
    "    \n",
    "posts_df = pd.DataFrame(posts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "024525ac-5bc5-418e-afcb-90dec17976a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>post_title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>time_created</th>\n",
       "      <th>post_url</th>\n",
       "      <th>flair_text</th>\n",
       "      <th>score</th>\n",
       "      <th>comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>vjpew4</td>\n",
       "      <td>Working with data is like...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1.656080e+09</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>395</td>\n",
       "      <td>32</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>9lprhw</td>\n",
       "      <td>The Intro to Data Science course at UC Berkele...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1.538770e+09</td>\n",
       "      <td>https://i.redd.it/mh4zp1hxbfq11.jpg</td>\n",
       "      <td>None</td>\n",
       "      <td>377</td>\n",
       "      <td>92</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>bc0lka</td>\n",
       "      <td>A Google Brain Program Is Learning How to Program</td>\n",
       "      <td>artificial</td>\n",
       "      <td>1.554993e+09</td>\n",
       "      <td>https://medium.com/syncedreview/a-google-brain...</td>\n",
       "      <td>None</td>\n",
       "      <td>91</td>\n",
       "      <td>23</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>10y2rrx</td>\n",
       "      <td>Thoughts?</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1.675969e+09</td>\n",
       "      <td>https://i.redd.it/l269tf8x39ha1.jpg</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>1690</td>\n",
       "      <td>193</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>9psua7</td>\n",
       "      <td>If you've been wondering about the disappearan...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1.540029e+09</td>\n",
       "      <td>https://www.reddit.com/r/datascience/comments/...</td>\n",
       "      <td>None</td>\n",
       "      <td>276</td>\n",
       "      <td>30</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>oyjemy</td>\n",
       "      <td>Small and wide data is important and relevant:...</td>\n",
       "      <td>artificial</td>\n",
       "      <td>1.628174e+09</td>\n",
       "      <td>https://signum.ai/blog/small-and-wide-data-is-...</td>\n",
       "      <td>Discussion</td>\n",
       "      <td>84</td>\n",
       "      <td>5</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1897</th>\n",
       "      <td>vx7mx0</td>\n",
       "      <td>Every higher level management - \"We have data,...</td>\n",
       "      <td>datascience</td>\n",
       "      <td>1.657620e+09</td>\n",
       "      <td>https://i.redd.it/x2d2akh160b91.png</td>\n",
       "      <td>Fun/Trivia</td>\n",
       "      <td>277</td>\n",
       "      <td>24</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>da2cna</td>\n",
       "      <td>[N] Amidst controversy regarding his most rece...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>1.569600e+09</td>\n",
       "      <td>https://www.reddit.com/r/MachineLearning/comme...</td>\n",
       "      <td>News</td>\n",
       "      <td>345</td>\n",
       "      <td>113</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>t37al0</td>\n",
       "      <td>[R] Robotic Telekinesis: Controlling Multifing...</td>\n",
       "      <td>MachineLearning</td>\n",
       "      <td>1.646024e+09</td>\n",
       "      <td>https://v.redd.it/820q8hyv8ik81</td>\n",
       "      <td>Research</td>\n",
       "      <td>430</td>\n",
       "      <td>9</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>xoqe06</td>\n",
       "      <td>AI audio is on the rise and will spark new deb...</td>\n",
       "      <td>artificial</td>\n",
       "      <td>1.664215e+09</td>\n",
       "      <td>https://the-decoder.com/ai-audio-is-on-the-ris...</td>\n",
       "      <td>News</td>\n",
       "      <td>84</td>\n",
       "      <td>28</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_id                                         post_title  \\\n",
       "1313   vjpew4                       Working with data is like...   \n",
       "1379   9lprhw  The Intro to Data Science course at UC Berkele...   \n",
       "2842   bc0lka  A Google Brain Program Is Learning How to Program   \n",
       "104   10y2rrx                                          Thoughts?   \n",
       "1909   9psua7  If you've been wondering about the disappearan...   \n",
       "2894   oyjemy  Small and wide data is important and relevant:...   \n",
       "1897   vx7mx0  Every higher level management - \"We have data,...   \n",
       "1618   da2cna  [N] Amidst controversy regarding his most rece...   \n",
       "1099   t37al0  [R] Robotic Telekinesis: Controlling Multifing...   \n",
       "2917   xoqe06  AI audio is on the rise and will spark new deb...   \n",
       "\n",
       "            subreddit  time_created  \\\n",
       "1313      datascience  1.656080e+09   \n",
       "1379      datascience  1.538770e+09   \n",
       "2842       artificial  1.554993e+09   \n",
       "104       datascience  1.675969e+09   \n",
       "1909      datascience  1.540029e+09   \n",
       "2894       artificial  1.628174e+09   \n",
       "1897      datascience  1.657620e+09   \n",
       "1618  MachineLearning  1.569600e+09   \n",
       "1099  MachineLearning  1.646024e+09   \n",
       "2917       artificial  1.664215e+09   \n",
       "\n",
       "                                               post_url  flair_text  score  \\\n",
       "1313  https://www.reddit.com/r/datascience/comments/...  Discussion    395   \n",
       "1379                https://i.redd.it/mh4zp1hxbfq11.jpg        None    377   \n",
       "2842  https://medium.com/syncedreview/a-google-brain...        None     91   \n",
       "104                 https://i.redd.it/l269tf8x39ha1.jpg  Discussion   1690   \n",
       "1909  https://www.reddit.com/r/datascience/comments/...        None    276   \n",
       "2894  https://signum.ai/blog/small-and-wide-data-is-...  Discussion     84   \n",
       "1897                https://i.redd.it/x2d2akh160b91.png  Fun/Trivia    277   \n",
       "1618  https://www.reddit.com/r/MachineLearning/comme...        News    345   \n",
       "1099                    https://v.redd.it/820q8hyv8ik81    Research    430   \n",
       "2917  https://the-decoder.com/ai-audio-is-on-the-ris...        News     84   \n",
       "\n",
       "      comments  upvote_ratio  \n",
       "1313        32          0.94  \n",
       "1379        92          0.98  \n",
       "2842        23          0.94  \n",
       "104        193          0.97  \n",
       "1909        30          0.98  \n",
       "2894         5          0.95  \n",
       "1897        24          0.98  \n",
       "1618       113          0.92  \n",
       "1099         9          0.97  \n",
       "2917        28          0.91  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the content\n",
    "posts_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae6c1b6-4617-4c92-99c8-7fe9dc025f1d",
   "metadata": {},
   "source": [
    "We will use the 'post_id' to further extract the comments from the top posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f46af94-f400-4a90-8651-5aead766b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_list = []\n",
    "\n",
    "for post_id in posts_df['post_id']:\n",
    "    submission = reddit.submission(post_id)\n",
    "    \n",
    "    submissi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3847cf49-6c66-4288-b8c1-f095c9766501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422ebdfc-0d34-4ebd-b0e2-ae163fe95479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a963c97-dd58-418f-bd53-06066144e754",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75609bbe-34ad-4d3a-9777-75e4258fe4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336af468-0497-4164-a5aa-034f0c3d9d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4237b9-af54-4788-a8ee-3d705831b5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reddit_project:Python",
   "language": "python",
   "name": "conda-env-reddit_project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
